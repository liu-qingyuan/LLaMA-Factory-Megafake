{
  "experiment_config": {
    "global": {
      "random_seed": 42,
      "output_base_dir": "experiments/sensitivity_analysis",
      "log_level": "INFO",
      "gpu_memory_fraction": 0.9,
      "max_concurrent_experiments": 1,
      "enable_checkpointing": true,
      "enable_auto_cleanup": true,
      "cleanup_interval": 10
    },
    "data_sensitivity": {
      "enabled": true,
      "datasets": {
        "task1_glm": {
          "path": "data/data_table/task1/alpaca_full/alpaca_megafake_glm_binary.json",
          "name": "Task1 GLM Binary",
          "description": "GLM生成的Task1二分类数据集"
        },
        "task1_llama": {
          "path": "data/data_table/task1/alpaca_full/alpaca_megafake_llama_binary.json",
          "name": "Task1 LLaMA Binary",
          "description": "LLaMA生成的Task1二分类数据集"
        },
        "task2_glm_style_based": {
          "path": "data/data_table/task2/alpaca_full/glm/alpaca_glm_style_based_fake.json",
          "name": "Task2 GLM Style-based",
          "description": "GLM风格基假新闻检测"
        },
        "task2_llama_content_based": {
          "path": "data/data_table/task2/alpaca_full/llama/alpaca_llama3_content_based_fake.json",
          "name": "Task2 LLaMA Content-based",
          "description": "LLaMA内容基假新闻检测"
        }
      },
      "data_sizes": [
        1000,
        2000,
        5000,
        10000,
        20000,
        "Full"
      ],
      "sampling": {
        "method": "stratified",
        "preserve_distribution": true,
        "min_samples_per_class": 50,
        "max_retries": 3
      },
      "quality_tests": {
        "enabled": true,
        "noise_levels": [
          0.0,
          0.1,
          0.2
        ],
        "noise_types": [
          "random",
          "systematic"
        ]
      }
    },
    "lora_sensitivity": {
      "enabled": true,
      "parameter_ranges": {
        "r": [
          8,
          16,
          32
        ],
        "alpha": [
          16,
          32,
          64
        ],
        "dropout": [
          0.0,
          0.1
        ]
      },
      "test_strategy": "grid_search",
      "max_combinations": 20
    },
    "training_sensitivity": {
      "enabled": true,
      "parameter_ranges": {
        "batch_size": [
          8,
          16
        ],
        "learning_rate": [
          "1e-5",
          "2e-5",
          "5e-5"
        ],
        "epochs": [
          1,
          3
        ]
      },
      "training": {
        "gradient_accumulation_steps": 1,
        "warmup_ratio": 0.1,
        "weight_decay": 0.01,
        "max_grad_norm": 1.0,
        "lr_scheduler_type": "cosine"
      }
    },
    "inference_sensitivity": {
      "enabled": true,
      "parameter_ranges": {
        "temperature": [
          0.1,
          0.7,
          1.0
        ],
        "top_p": [
          0.8,
          0.9,
          0.95
        ],
        "max_new_tokens": [
          50,
          100
        ],
        "do_sample": [
          true,
          false
        ]
      }
    },
    "model_comparison": {
      "enabled": true,
      "models": [
        "llama3_8b",
        "chatglm3_6b",
        "qwen1_5_7b",
        "baichuan2_7b",
        "mistral_7b"
      ],
      "metrics": [
        "accuracy",
        "f1_macro",
        "precision",
        "recall",
        "inference_speed",
        "memory_usage"
      ],
      "comparison_dimensions": [
        "data_efficiency",
        "parameter_efficiency",
        "computational_efficiency",
        "robustness"
      ]
    },
    "evaluation": {
      "metrics": {
        "classification": [
          "accuracy",
          "f1_macro",
          "f1_micro",
          "precision",
          "recall",
          "auc"
        ],
        "efficiency": [
          "training_time",
          "inference_speed",
          "memory_usage",
          "gpu_utilization"
        ],
        "robustness": [
          "adversarial_resistance",
          "noise_tolerance"
        ]
      },
      "cross_validation": {
        "enabled": true,
        "folds": 3,
        "stratified": true
      }
    },
    "visualization": {
      "enabled": true,
      "plot_types": [
        "sensitivity_curves",
        "parameter_heatmaps",
        "performance_comparison",
        "efficiency_analysis",
        "robustness_analysis"
      ],
      "figure_settings": {
        "figsize": [
          12,
          8
        ],
        "dpi": 300,
        "format": "png",
        "style": "seaborn-v0_8",
        "color_palette": "viridis"
      }
    },
    "reporting": {
      "enabled": true,
      "formats": [
        "html",
        "pdf",
        "markdown"
      ],
      "sections": [
        "executive_summary",
        "methodology",
        "results",
        "analysis",
        "conclusions",
        "recommendations",
        "appendix"
      ]
    },
    "execution": {
      "parallel": {
        "enabled": false,
        "max_workers": 1
      },
      "checkpointing": {
        "enabled": true,
        "save_interval": 10,
        "keep_last_n": 3
      },
      "error_handling": {
        "max_retries": 3,
        "retry_delay": 60,
        "continue_on_error": true
      },
      "resource_management": {
        "memory_threshold": 0.9,
        "disk_threshold": 0.8,
        "gpu_monitoring": true
      }
    },
    "quick_test": {
      "enabled": true,
      "models": [
        "llama3_8b"
      ],
      "data_sizes": [
        1000,
        5000
      ],
      "lora_r": [
        16
      ],
      "batch_size": [
        16
      ],
      "cross_validation": {
        "folds": 2
      }
    }
  },
  "timestamp": "2025-11-15T20:59:21.220402",
  "total_experiments": 5,
  "completed_experiments": 5,
  "results": [
    {
      "experiment_id": "exp_000001",
      "model_name": "llama3_8b",
      "dataset_name": "task1_glm",
      "data_size": 1000,
      "metrics": {
        "accuracy": 0.6877623976390616,
        "f1_macro": 0.6663780436937877,
        "precision": 0.7130808258440027,
        "recall": 0.6827103056961306,
        "auc": 0.7458824373195296
      },
      "training_time": 6.0,
      "inference_time": 1.0,
      "memory_usage": 16.988962852336698,
      "status": "completed",
      "error_message": "",
      "timestamp": "2025-11-15T20:59:01.118285"
    },
    {
      "experiment_id": "exp_000002",
      "model_name": "llama3_8b",
      "dataset_name": "task1_glm",
      "data_size": 2000,
      "metrics": {
        "accuracy": 0.6977623976390616,
        "f1_macro": 0.6763780436937877,
        "precision": 0.7205808258440027,
        "recall": 0.6952103056961306,
        "auc": 0.7533824373195297
      },
      "training_time": 12.0,
      "inference_time": 2.0,
      "memory_usage": 16.988962852336698,
      "status": "completed",
      "error_message": "",
      "timestamp": "2025-11-15T20:59:06.139081"
    },
    {
      "experiment_id": "exp_000003",
      "model_name": "llama3_8b",
      "dataset_name": "task1_glm",
      "data_size": 5000,
      "metrics": {
        "accuracy": 0.7277623976390616,
        "f1_macro": 0.7063780436937878,
        "precision": 0.7430808258440027,
        "recall": 0.7327103056961306,
        "auc": 0.7758824373195297
      },
      "training_time": 30.0,
      "inference_time": 5.0,
      "memory_usage": 16.988962852336698,
      "status": "completed",
      "error_message": "",
      "timestamp": "2025-11-15T20:59:11.162241"
    },
    {
      "experiment_id": "exp_000004",
      "model_name": "llama3_8b",
      "dataset_name": "task1_glm",
      "data_size": 10000,
      "metrics": {
        "accuracy": 0.7777623976390615,
        "f1_macro": 0.7563780436937877,
        "precision": 0.7805808258440027,
        "recall": 0.7952103056961306,
        "auc": 0.8133824373195296
      },
      "training_time": 60.0,
      "inference_time": 10.0,
      "memory_usage": 16.988962852336698,
      "status": "completed",
      "error_message": "",
      "timestamp": "2025-11-15T20:59:16.187362"
    },
    {
      "experiment_id": "exp_000005",
      "model_name": "llama3_8b",
      "dataset_name": "task1_glm",
      "data_size": 20000,
      "metrics": {
        "accuracy": 0.8777623976390615,
        "f1_macro": 0.8563780436937878,
        "precision": 0.8555808258440027,
        "recall": 0.9202103056961306,
        "auc": 0.8883824373195297
      },
      "training_time": 120.0,
      "inference_time": 20.0,
      "memory_usage": 16.988962852336698,
      "status": "completed",
      "error_message": "",
      "timestamp": "2025-11-15T20:59:21.219429"
    }
  ]
}