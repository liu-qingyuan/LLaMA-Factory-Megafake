# é—®é¢˜æ’æŸ¥æŒ‡å—

## ğŸ”§ å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ

### 1. å¯¼å…¥è·¯å¾„é”™è¯¯

#### é—®é¢˜æè¿°
```
ModuleNotFoundError: No module named 'utils.config'
ModuleNotFoundError: No module named 'sensitivity_analysis.scripts.core'
```

#### åŸå› åˆ†æ
- ç›®å½•é‡ç»„åå¯¼å…¥è·¯å¾„å¤±æ•ˆ
- Pythonè·¯å¾„é…ç½®ä¸æ­£ç¡®
- æ¨¡å—åˆå§‹åŒ–æ–‡ä»¶ç¼ºå¤±

#### è§£å†³æ–¹æ¡ˆ

**æ–¹æ¡ˆ1: ä½¿ç”¨ç»Ÿä¸€å…¥å£è„šæœ¬**
```bash
# æ¨èä½¿ç”¨æ–¹å¼
python scripts/sa.py quick
```

**æ–¹æ¡ˆ2: æ‰‹åŠ¨ä¿®å¤è·¯å¾„**
```python
# åœ¨è„šæœ¬å¼€å¤´æ·»åŠ 
import sys
from pathlib import Path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
```

**æ–¹æ¡ˆ3: éªŒè¯å¯¼å…¥ä¿®å¤**
```bash
python sensitivity_analysis/scripts/test_vllm_fix.py
```

### 2. VLLMæ¨ç†é”™è¯¯

#### é—®é¢˜æè¿°
```
VLLM evaluation failed: No module named 'utils.config'
VLLM inference failed: CUDA error
```

#### è§£å†³æ–¹æ¡ˆ

**æ­¥éª¤1: éªŒè¯é…ç½®å¯¼å…¥**
```bash
python -c "
from sensitivity_analysis.configs.config import MODEL_CONFIGS
print('é…ç½®å¯¼å…¥æˆåŠŸ:', len(MODEL_CONFIGS), 'ä¸ªæ¨¡å‹')
"
```

**æ­¥éª¤2: æ£€æŸ¥VLLMå®‰è£…**
```bash
python -c "
from llamafactory.extras.packages import is_vllm_available
print('VLLMå¯ç”¨:', is_vllm_available())
"
```

**æ­¥éª¤3: è¿è¡Œæµ‹è¯•è„šæœ¬**
```bash
python sensitivity_analysis/scripts/test_vllm_fix.py
```

### 3. CUDAå†…å­˜é”™è¯¯

#### é—®é¢˜æè¿°
```
CUDA error: device-side assert triggered
RuntimeError: CUDA out of memory
```

#### è§£å†³æ–¹æ¡ˆ

**ç«‹å³æªæ–½**
```bash
# æ£€æŸ¥GPUçŠ¶æ€
nvidia-smi

# æ¸…ç†GPUç¼“å­˜
nvidia-smi --gpu-reset
```

**ä»£ç è°ƒæ•´**
```python
# å‡å°‘æ‰¹æ¬¡å¤§å°
batch_size = 4  # ä»8å‡å°‘åˆ°4

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
gradient_checkpointing = True

# ä½¿ç”¨æ··åˆç²¾åº¦
fp16 = True
```

**é…ç½®ä¼˜åŒ–**
```yaml
# åœ¨é…ç½®æ–‡ä»¶ä¸­
per_device_train_batch_size: 1
gradient_accumulation_steps: 16
fp16: true
flash_attn: "auto"
```

### 4. æ¨¡å‹åŠ è½½é”™è¯¯

#### é—®é¢˜æè¿°
```
OSError: Can't load tokenizer for 'xxx'
FileNotFoundError: [Errno 2] No such file or directory: 'model_name'
```

#### è§£å†³æ–¹æ¡ˆ

**æ£€æŸ¥æ¨¡å‹è·¯å¾„**
```bash
# éªŒè¯æ¨¡å‹å­˜åœ¨
ls -la /root/autodl-tmp/models/

# æ£€æŸ¥æ¨¡å‹å®Œæ•´æ€§
python -c "
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained('/root/autodl-tmp/models/Qwen1.5-7B')
print('æ¨¡å‹åŠ è½½æˆåŠŸ')
"
```

**ä¿®å¤æ¨¡å‹é…ç½®**
```python
# æ›´æ–°MODEL_CONFIGS
MODEL_CONFIGS = {
    "/root/autodl-tmp/models/Qwen1.5-7B": ("qwen", True),
    # ç¡®ä¿è·¯å¾„æ­£ç¡®
}
```

### 5. æ•°æ®é›†é”™è¯¯

#### é—®é¢˜æè¿°
```
FileNotFoundError: [Errno 2] No such file or directory: 'dataset_file'
DatasetDicté”™è¯¯: æ•°æ®é›†æ ¼å¼ä¸æ­£ç¡®
```

#### è§£å†³æ–¹æ¡ˆ

**éªŒè¯æ•°æ®é›†è·¯å¾„**
```bash
# æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶
find data/ -name "*.json" -o -name "*.jsonl"

# éªŒè¯æ•°æ®é›†æ³¨å†Œ
python -c "
import json
with open('data/dataset_info.json', 'r') as f:
    datasets = json.load(f)
print('æ•°æ®é›†æ•°é‡:', len(datasets))
"
```

**ä¿®å¤æ•°æ®é›†è·¯å¾„**
```python
# ä½¿ç”¨ç›¸å¯¹è·¯å¾„
DATASET_CONFIGS = {
    "task1_small_glm": "data/data_table/task1/small_8k/alpaca_megafake_glm_8k.json",
    # ç¡®ä¿è·¯å¾„ä»é¡¹ç›®æ ¹ç›®å½•å¼€å§‹
}
```

### 6. è®­ç»ƒä¸­æ–­é”™è¯¯

#### é—®é¢˜æè¿°
```
è®­ç»ƒè¿‡ç¨‹ä¸­çªç„¶åœæ­¢
è¿›ç¨‹è¢«æ€æ­»
å®éªŒç»“æœä¸å®Œæ•´
```

#### è§£å†³æ–¹æ¡ˆ

**æ£€æŸ¥ç³»ç»Ÿèµ„æº**
```bash
# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
free -h

# æŸ¥çœ‹ç£ç›˜ç©ºé—´
df -h

# æŸ¥çœ‹GPUä½¿ç”¨
nvidia-smi -l 1
```

**å¯ç”¨å®éªŒæ¢å¤**
```python
# åœ¨è„šæœ¬ä¸­æ·»åŠ æ–­ç‚¹ç»­è®­
resume_from_checkpoint: "latest"
```

**ä½¿ç”¨åå°è¿è¡Œ**
```bash
# ä½¿ç”¨tmuxè¿è¡Œ
tmux new -s sensitivity
python scripts/sa.py quick

# ä½¿ç”¨nohupè¿è¡Œ
nohup python scripts/sa.py quick > experiment.log 2>&1 &
```

### 7. æ€§èƒ½é—®é¢˜

#### é—®é¢˜æè¿°
```
æ¨ç†é€Ÿåº¦æ…¢
è®­ç»ƒæ—¶é—´é•¿
å†…å­˜ä½¿ç”¨è¿‡é«˜
```

#### è§£å†³æ–¹æ¡ˆ

**å¯ç”¨åŠ é€Ÿ**
```python
# Flash Attention
flash_attn: "auto"

# VLLMåŠ é€Ÿ
VLLM_ENABLED=true python scripts/sa.py quick

# æ··åˆç²¾åº¦
fp16: true
bf16: true
```

**ä¼˜åŒ–é…ç½®**
```yaml
# æ¨ç†ä¼˜åŒ–
per_device_eval_batch_size: 32
max_new_tokens: 10  # å‡å°‘ç”Ÿæˆé•¿åº¦

# è®­ç»ƒä¼˜åŒ–
dataloader_num_workers: 4
preprocessing_num_workers: 16
```

### 8. ä¾èµ–é—®é¢˜

#### é—®é¢˜æè¿°
```
ImportError: No module named 'transformers'
ç‰ˆæœ¬å†²çª: incompatible versions
```

#### è§£å†³æ–¹æ¡ˆ

**é‡æ–°å®‰è£…ä¾èµ–**
```bash
# å¸è½½æ—§ç‰ˆæœ¬
pip uninstall transformers peft accelerate

# é‡æ–°å®‰è£…
pip install transformers>=4.30.0 peft>=0.4.0 accelerate>=0.20.0
```

**æ£€æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§**
```bash
python -c "
import transformers
import peft
import accelerate
print('transformers:', transformers.__version__)
print('peft:', peft.__version__)
print('accelerate:', accelerate.__version__)
"
```

## ğŸ” è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—
```bash
export PYTHONPATH=/root/autodl-tmp/LLaMA-Factory-Megafake:$PYTHONPATH
export CUDA_LAUNCH_BLOCKING=1
```

### 2. ä½¿ç”¨è°ƒè¯•æ¨¡å¼
```python
import logging
logging.basicConfig(level=logging.DEBUG)

# æˆ–åœ¨é…ç½®ä¸­
debug: true
```

### 3. åˆ†æ­¥éªŒè¯
```bash
# ç¬¬1æ­¥: æµ‹è¯•é…ç½®
python scripts/sa.py test

# ç¬¬2æ­¥: å¿«é€Ÿåˆ†æ
python scripts/sa.py quick

# ç¬¬3æ­¥: ç›‘æ§çŠ¶æ€
python scripts/sa.py monitor
```

### 4. æŸ¥çœ‹æ—¥å¿—
```bash
# æŸ¥çœ‹æœ€æ–°æ—¥å¿—
tail -f sensitivity_analysis/results/logs/*.log

# æœç´¢é”™è¯¯
grep -i error sensitivity_analysis/results/logs/*.log
```

## ğŸ“ è·å–å¸®åŠ©

### 1. è¿è¡Œè¯Šæ–­è„šæœ¬
```bash
python sensitivity_analysis/scripts/test_vllm_fix.py
python sensitivity_analysis/model_utils/verify_models.py
```

### 2. æ”¶é›†é”™è¯¯ä¿¡æ¯
```bash
# æ”¶é›†ç³»ç»Ÿä¿¡æ¯
nvidia-smi
free -h
df -h
python --version

# æ”¶é›†é”™è¯¯æ—¥å¿—
ls -la sensitivity_analysis/results/logs/
```

### 3. å‚è€ƒæ–‡æ¡£
- [ç”¨æˆ·æ‰‹å†Œ](README.md)
- [è®¾ç½®æŒ‡å—](SETUP.md)
- [é¡¹ç›®ä¸»æ–‡æ¡£](../../CLAUDE.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-17
**ç»´æŠ¤çŠ¶æ€**: âœ… æ´»è·ƒç»´æŠ¤ä¸­