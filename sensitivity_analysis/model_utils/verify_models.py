#!/usr/bin/env python3
"""
æ¨¡å‹éªŒè¯å·¥å…· - æ•´åˆæ‰€æœ‰æ¨¡å‹éªŒè¯åŠŸèƒ½
"""

import os
import sys
import argparse
import subprocess
import logging
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
sensitivity_analysis_root = current_dir.parent
project_root = sensitivity_analysis_root.parent

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(project_root))

# å¯¼å…¥é…ç½® - ä¼˜å…ˆä½¿ç”¨æ–°çš„è·¯å¾„
try:
    from sensitivity_analysis.configs.config import MODEL_CONFIGS
except ImportError:
    try:
        from scripts.utils.config import MODEL_CONFIGS
    except ImportError:
        # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œå°è¯•ç›´æ¥å¯¼å…¥
        sys.path.insert(0, str(sensitivity_analysis_root / "configs"))
        from config import MODEL_CONFIGS

class ModelVerifier:
    """æ¨¡å‹éªŒè¯å™¨"""

    def __init__(self):
        self.logger = self.setup_logging()
        self.model_dir = Path("/root/autodl-tmp/models")

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)

    def get_available_models(self) -> List[str]:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        if not self.model_dir.exists():
            self.logger.error(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {self.model_dir}")
            return []

        model_preferences = [
            "Qwen1.5-7B",
            "Meta-Llama-3.1-8B-Instruct",
            "Baichuan2-7B-Chat",
            "Mistral-7B-v0.1",
            "chatglm3-6b"
        ]

        available = []
        for model in model_preferences:
            model_path = self.model_dir / model
            if model_path.is_dir():
                available.append(model)

        return available

    def test_basic_loading(self, model_name: str) -> bool:
        """æµ‹è¯•åŸºç¡€æ¨¡å‹åŠ è½½"""
        try:
            model_path = str(self.model_dir / model_name)

            # ç®€å•çš„åŠ è½½æµ‹è¯•
            import transformers
            tokenizer = transformers.AutoTokenizer.from_pretrained(
                model_path,
                trust_remote_code=True
            )
            model = transformers.AutoModelForCausalLM.from_pretrained(
                model_path,
                trust_remote_code=True,
                torch_dtype="auto",
                device_map="auto"
            )

            # ç®€å•æ¨ç†æµ‹è¯•
            inputs = tokenizer("Hello", return_tensors="pt")
            outputs = model.generate(**inputs, max_new_tokens=1)

            self.logger.info(f"âœ… {model_name}: åŸºç¡€åŠ è½½æˆåŠŸ")
            return True

        except Exception as e:
            self.logger.error(f"âŒ {model_name}: åŸºç¡€åŠ è½½å¤±è´¥ - {e}")
            return False

    def test_llamafactory_compatibility(self, model_name: str) -> bool:
        """æµ‹è¯•LLaMA-Factoryå…¼å®¹æ€§"""
        try:
            # åˆ›å»ºæµ‹è¯•é…ç½®
            import tempfile
            import yaml

            model_path = str(self.model_dir / model_name)
            template = MODEL_CONFIGS.get(model_path, ("qwen", True))[0]

            config = {
                "model_name_or_path": model_path,
                "template": template,
                "stage": "sft",
                "do_train": False,
                "dataset": "alpaca_en_demo",
                "max_samples": 1,
                "output_dir": tempfile.mkdtemp()
            }

            with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
                yaml.dump(config, f)
                config_file = f.name

            # è¿è¡Œæµ‹è¯•
            cmd = ["llamafactory-cli", "train", config_file]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)

            # æ¸…ç†
            os.unlink(config_file)
            os.makedirs(config["output_dir"], exist_ok=True)

            if result.returncode == 0:
                self.logger.info(f"âœ… {model_name}: LLaMA-Factoryå…¼å®¹")
                return True
            else:
                self.logger.error(f"âŒ {model_name}: LLaMA-Factoryä¸å…¼å®¹ - {result.stderr}")
                return False

        except Exception as e:
            self.logger.error(f"âŒ {model_name}: LLaMA-Factoryæµ‹è¯•å¼‚å¸¸ - {e}")
            return False

    def test_vllm_compatibility(self, model_name: str) -> bool:
        """æµ‹è¯•VLLMå…¼å®¹æ€§"""
        try:
            model_path = str(self.model_dir / model_name)
            template = MODEL_CONFIGS.get(model_path, ("qwen", True))[0]

            # åˆ›å»ºä¸´æ—¶è¾“å‡º
            import tempfile
            temp_output = tempfile.NamedTemporaryFile(suffix='.jsonl', delete=False)
            temp_output.close()

            cmd = [
                "python", "scripts/vllm_infer.py",
                "--model_name_or_path", model_path,
                "--template", template,
                "--dataset", "alpaca_en_demo",
                "--save_name", temp_output.name,
                "--max_new_tokens", "5",
                "--max_samples", "1"
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

            # æ¸…ç†
            try:
                os.unlink(temp_output.name)
            except:
                pass

            if result.returncode == 0:
                self.logger.info(f"âœ… {model_name}: VLLMå…¼å®¹")
                return True
            else:
                self.logger.error(f"âŒ {model_name}: VLLMä¸å…¼å®¹ - {result.stderr}")
                return False

        except Exception as e:
            self.logger.error(f"âŒ {model_name}: VLLMæµ‹è¯•å¼‚å¸¸ - {e}")
            return False

    def generate_report(self, results: Dict[str, Dict[str, bool]]) -> str:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        report = ["# æ¨¡å‹éªŒè¯æŠ¥å‘Š\n"]
        report.append(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")

        # ç»Ÿè®¡
        total = len(results)
        basic_ok = sum(1 for r in results.values() if r["basic_loading"])
        factory_ok = sum(1 for r in results.values() if r["llamafactory"])
        vllm_ok = sum(1 for r in results.values() if r["vllm"])

        report.append("## ç»Ÿè®¡æ‘˜è¦")
        report.append(f"- æ€»æ¨¡å‹æ•°: {total}")
        report.append(f"- åŸºç¡€åŠ è½½æˆåŠŸ: {basic_ok}/{total}")
        report.append(f"- LLaMA-Factoryå…¼å®¹: {factory_ok}/{total}")
        report.append(f"- VLLMå…¼å®¹: {vllm_ok}/{total}\n")

        # è¯¦ç»†ç»“æœ
        report.append("## è¯¦ç»†ç»“æœ\n")
        for model, result in results.items():
            status = "âœ…" if all(result.values()) else "âš ï¸"
            report.append(f"### {model} {status}")
            report.append(f"- åŸºç¡€åŠ è½½: {'âœ…' if result['basic_loading'] else 'âŒ'}")
            report.append(f"- LLaMA-Factory: {'âœ…' if result['llamafactory'] else 'âŒ'}")
            report.append(f"- VLLM: {'âœ…' if result['vllm'] else 'âŒ'}\n")

        return "\n".join(report)

    def run_verification(self, tests: List[str] = None) -> bool:
        """è¿è¡Œæ¨¡å‹éªŒè¯"""
        if tests is None:
            tests = ["basic_loading", "llamafactory", "vllm"]

        models = self.get_available_models()
        if not models:
            self.logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨æ¨¡å‹")
            return False

        self.logger.info(f"ğŸ” å¼€å§‹éªŒè¯ {len(models)} ä¸ªæ¨¡å‹...")

        results = {}
        for model in models:
            self.logger.info(f"ğŸ§ª éªŒè¯æ¨¡å‹: {model}")

            result = {}

            if "basic_loading" in tests:
                result["basic_loading"] = self.test_basic_loading(model)

            if "llamafactory" in tests:
                result["llamafactory"] = self.test_llamafactory_compatibility(model)

            if "vllm" in tests:
                result["vllm"] = self.test_vllm_compatibility(model)

            results[model] = result

        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report(results)

        # ä¿å­˜æŠ¥å‘Š
        report_path = "model_verification_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        self.logger.info(f"ğŸ“„ éªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

        # æ‰“å°æ‘˜è¦
        all_ok = all(all(r.values()) for r in results.values())
        if all_ok:
            self.logger.info("ğŸ‰ æ‰€æœ‰æ¨¡å‹éªŒè¯é€šè¿‡ï¼")
        else:
            self.logger.warning("âš ï¸ éƒ¨åˆ†æ¨¡å‹éªŒè¯å¤±è´¥ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š")

        return all_ok

def main():
    parser = argparse.ArgumentParser(description="æ¨¡å‹éªŒè¯å·¥å…·")
    parser.add_argument("--tests", nargs="+",
                       choices=["basic_loading", "llamafactory", "vllm"],
                       default=["basic_loading", "llamafactory", "vllm"],
                       help="é€‰æ‹©è¦è¿è¡Œçš„æµ‹è¯•")

    args = parser.parse_args()

    verifier = ModelVerifier()
    success = verifier.run_verification(args.tests)

    sys.exit(0 if success else 1)

if __name__ == "__main__":
    import time
    main()